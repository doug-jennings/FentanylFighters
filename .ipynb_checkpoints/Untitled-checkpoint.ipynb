{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4efa91a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"Missing\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"Missing\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6936\\1147934620.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Convert Deaths column to numeric data type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mdata_without_totals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Deaths'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_without_totals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Deaths'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Group by year and sum non-suppressed values for each age bracket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4432\u001b[0m         \"\"\"\n\u001b[1;32m-> 4433\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mcoerce_numeric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             values, _ = lib.maybe_convert_numeric(\n\u001b[0m\u001b[0;32m    185\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"Missing\" at position 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_excel('total_deaths.xlsx', engine='openpyxl')\n",
    "\n",
    "# Remove the rows containing total values\n",
    "data_without_totals = data[data['County'].notna()]\n",
    "\n",
    "# Melt the dataset to have a Year column\n",
    "data_without_totals = pd.melt(data_without_totals, id_vars=['Notes', 'County', 'County Code'], var_name='Year', value_name='Deaths')\n",
    "\n",
    "# Count suppressed values\n",
    "suppressed_counts = data_without_totals.groupby('Year').apply(lambda x: (x['Deaths'] == 'Suppressed').sum())\n",
    "\n",
    "# Replace suppressed values with NaN\n",
    "data_without_totals.replace('Suppressed', pd.NA, inplace=True)\n",
    "\n",
    "# Convert Deaths column to numeric data type\n",
    "data_without_totals['Deaths'] = data_without_totals['Deaths'].apply(pd.to_numeric)\n",
    "\n",
    "# Group by year and sum non-suppressed values for each age bracket\n",
    "non_suppressed_totals = data_without_totals.groupby('Year')['Deaths'].sum(skipna=True)\n",
    "\n",
    "# Extract the rows containing total values\n",
    "total_values = data_without_totals[data_without_totals['County'].isna()].set_index('Year').drop(columns=['County Code'])\n",
    "total_values.replace('Suppressed', 0, inplace=True)\n",
    "\n",
    "suppressed_totals = total_values - non_suppressed_totals\n",
    "\n",
    "# Replace suppressed values with suppressed_totals divided by the number of suppressed values\n",
    "replacement_values = suppressed_totals / suppressed_counts\n",
    "replacement_values = replacement_values.reset_index()\n",
    "\n",
    "def replace_suppressed(row, replacement_df):\n",
    "    year = row['Year']\n",
    "    if pd.isna(row['Deaths']):\n",
    "        replacement_value = replacement_df.loc[(replacement_df['Year'] == year), 'Deaths'].iloc[0]\n",
    "        row['Deaths'] = replacement_value\n",
    "    return row\n",
    "\n",
    "data_without_totals['Deaths'] = data_without_totals.apply(lambda x: replace_suppressed(x, replacement_values), axis=1)\n",
    "\n",
    "# Pivot the dataset back to the original format\n",
    "data_without_totals = data_without_totals.pivot_table(values='Deaths', index=['Notes', 'County', 'County Code'], columns='Year', aggfunc='sum').reset_index()\n",
    "\n",
    "# Save the resulting dataset to a new xlsx file\n",
    "with pd.ExcelWriter('death_data_replaced.xlsx', engine='openpyxl') as writer:\n",
    "    data_without_totals.to_excel(writer, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ea905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data from the files\n",
    "death_data_replaced_df = pd.read_excel('death_data_replaced.xlsx')\n",
    "death_data_white_df = pd.read_excel('death_data_white.xlsx')\n",
    "unemployment_med_inc_df = pd.read_excel('unemployment-med-hh-inc.xlsx')\n",
    "\n",
    "# Remove rows where the 'Area_name' field doesn't contain a comma\n",
    "unemployment_med_inc_df = unemployment_med_inc_df[unemployment_med_inc_df['Area_name'].str.contains(',')]\n",
    "\n",
    "# Create separate dataframes for each year and merge them later\n",
    "years = range(2013, 2021)\n",
    "merged_dfs = []\n",
    "\n",
    "for year in years:\n",
    "    # Extract relevant columns for the current year\n",
    "    cols = ['FIPS', f'Civilian_labor_force_{year}', f'Employed_{year}', f'Unemployed_{year}', f'Unemployment_rate_{year}']\n",
    "    if year == 2020:\n",
    "        cols.extend(['Median_Household_Income_2020', 'Med_HH_Income_Percent_of_State_Total_2020'])\n",
    "    unemployment_med_inc_year_df = unemployment_med_inc_df[cols]\n",
    "    unemployment_med_inc_year_df['Year'] = year\n",
    "    \n",
    "    # Merge the datasets for the current year\n",
    "    merged_year_df = pd.merge(disp_rates_df[disp_rates_df['Year'] == year], race_pop_df[race_pop_df['Year'] == year], on=['FIPS', 'Year'])\n",
    "    merged_year_df = pd.merge(merged_year_df, unemployment_med_inc_year_df, on=['FIPS', 'Year'])\n",
    "    \n",
    "    # Append the merged dataframe for the current year to the list\n",
    "    merged_dfs.append(merged_year_df)\n",
    "\n",
    "# Concatenate the dataframes for all years\n",
    "merged_df = pd.concat(merged_dfs, ignore_index=True)\n",
    "\n",
    "# Write the result to an xlsx file\n",
    "merged_df.to_excel('data.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
