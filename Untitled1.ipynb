{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbdb20bb",
   "metadata": {},
   "source": [
    "Yearly opioid overdoses per county were gathered from https://wonder.cdc.gov/mcd-icd10.html.\n",
    "To replace suppressed values with an estimate, yearly_death_totals was compiled from the same source.\n",
    "The cell below creates a new column for each year rather than leaving 'year' as a single column \n",
    "and replaces suppressed values (values less than 10) with \n",
    "(yearly_death_totals - unsuppressed_vals)/num_suppressed_entries) for each year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f81a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from the files\n",
    "data = pd.read_excel(\"all_deaths.xlsx\")\n",
    "yearly_death_totals_data = pd.read_excel(\"yearly_death_totals.xlsx\")\n",
    "\n",
    "# Pivot the data using the pivot_table function\n",
    "pivoted_data = data.pivot_table(index=['County', 'County Code'],\n",
    "                                columns='Year',\n",
    "                                values=['Deaths', 'Population'],\n",
    "                                aggfunc='first').reset_index()\n",
    "\n",
    "# Flatten the column names\n",
    "pivoted_data.columns.name = None\n",
    "pivoted_data.columns = [f'{col[0]}_{col[1]}' if col[1] else col[0] for col in pivoted_data.columns]\n",
    "\n",
    "# Calculate suppressed values\n",
    "for year in range(2013, 2021):\n",
    "    yearly_death_totals = yearly_death_totals_data[f'yearly_death_totals{year}'].iloc[0]\n",
    "    unsuppressed_deaths = pivoted_data.loc[pivoted_data[f'Deaths_{year}'] != 'Suppressed', f'Deaths_{year}'].sum()\n",
    "    num_suppressed_entries = (pivoted_data[f'Deaths_{year}'] == 'Suppressed').sum()\n",
    "    \n",
    "    if num_suppressed_entries > 0:\n",
    "        suppressed_value = (yearly_death_totals - unsuppressed_deaths) / num_suppressed_entries\n",
    "    else:\n",
    "        suppressed_value = 0\n",
    "        \n",
    "    # Replace 'Suppressed' values with the calculated suppressed_value\n",
    "    pivoted_data.loc[pivoted_data[f'Deaths_{year}'] == 'Suppressed', f'Deaths_{year}'] = suppressed_value\n",
    "\n",
    "# Export the updated pivoted data to a new Excel file\n",
    "pivoted_data.to_excel(\"yearly_deaths.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0887472",
   "metadata": {},
   "source": [
    "We found that the death rate is correlated with the white population, so we will use the white proportion of county populations as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cabaf6f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the white_population data from the file\n",
    "white_population_data = pd.read_excel(\"white_population.xlsx\")\n",
    "\n",
    "# Pivot the data using the pivot_table function\n",
    "pivoted_white_population = white_population_data.pivot_table(index=['County', 'FIPS'],\n",
    "                                                              columns='Year',\n",
    "                                                              values='Population',\n",
    "                                                              aggfunc='first').reset_index()\n",
    "\n",
    "# Flatten the column names\n",
    "pivoted_white_population.columns.name = None\n",
    "pivoted_white_population.columns = [f'{col[0]}_{col[1]}' if isinstance(col, tuple) else col for col in pivoted_white_population.columns]\n",
    "\n",
    "# Export the pivoted data\n",
    "pivoted_white_population.to_excel(\"yearly_white_population.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46fc7996",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 County   FIPS  Deaths_2013  Deaths_2014  Deaths_2015  \\\n",
      "0  Abbeville County, SC  45001      1.82925     1.824377     1.919068   \n",
      "1     Acadia Parish, LA  22001      1.82925     1.824377     1.919068   \n",
      "2   Accomack County, VA  51001      1.82925     1.824377     1.919068   \n",
      "3        Ada County, ID  16001     38.00000    36.000000    22.000000   \n",
      "4      Adair County, IA  19001      1.82925     1.824377     1.919068   \n",
      "\n",
      "   Deaths_2016  Deaths_2017  Deaths_2018  Deaths_2019  Deaths_2020  ...  \\\n",
      "0     1.925623     2.031753     1.967213     2.012048     2.229486  ...   \n",
      "1     1.925623     2.031753     1.967213     2.012048     2.229486  ...   \n",
      "2     1.925623     2.031753     1.967213     2.012048     2.229486  ...   \n",
      "3    30.000000    35.000000    49.000000    46.000000    52.000000  ...   \n",
      "4     1.925623     2.031753     1.967213     2.012048     2.229486  ...   \n",
      "\n",
      "   Population_2019_white  Population_2020_white  Proportion_White_2013  \\\n",
      "0                  17269                  17259               0.696285   \n",
      "1                  49568                  49305               0.800543   \n",
      "2                  21802                  21750               0.680614   \n",
      "3                 442897                 453938               0.925770   \n",
      "4                   6914                   6853               0.972832   \n",
      "\n",
      "   Proportion_White_2014  Proportion_White_2015  Proportion_White_2016  \\\n",
      "0               0.692850               0.695331               0.692787   \n",
      "1               0.800531               0.798408               0.800096   \n",
      "2               0.682081               0.680163               0.678848   \n",
      "3               0.924448               0.921937               0.923723   \n",
      "4               0.970486               0.970393               0.966723   \n",
      "\n",
      "   Proportion_White_2017 Proportion_White_2018  Proportion_White_2019  \\\n",
      "0               0.697678              0.704413               0.704081   \n",
      "1               0.797284              0.797202               0.798904   \n",
      "2               0.681979              0.681970               0.674650   \n",
      "3               0.921206              0.918466               0.919661   \n",
      "4               0.976609              0.972250               0.966723   \n",
      "\n",
      "   Proportion_White_2020  \n",
      "0                0.70722  \n",
      "1               0.796295  \n",
      "2                0.67467  \n",
      "3               0.918161  \n",
      "4               0.970817  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the yearly_deaths and yearly_white_population data from the files\n",
    "yearly_deaths = pd.read_excel(\"yearly_deaths.xlsx\")\n",
    "yearly_white_population = pd.read_excel(\"yearly_white_population.xlsx\")\n",
    "\n",
    "# Rename the columns in the yearly_white_population DataFrame\n",
    "yearly_white_population.columns = [\n",
    "    f\"Population_{col}_white\" if isinstance(col, int) else col for col in yearly_white_population.columns\n",
    "]\n",
    "\n",
    "# Merge the DataFrames on the ['County', 'FIPS'] columns\n",
    "merged_data = yearly_deaths.merge(yearly_white_population, on=['County', 'FIPS'])\n",
    "\n",
    "# Calculate the proportion of the white population for each year and create new columns\n",
    "for year in range(2013, 2021):\n",
    "    merged_data[f'Proportion_White_{year}'] = merged_data[f'Population_{year}_white'] / merged_data[f'Population_{year}']\n",
    "\n",
    "# Display the updated merged_data DataFrame\n",
    "print(merged_data.head())\n",
    "\n",
    "\n",
    "# Export the updated merged_data DataFrame\n",
    "merged_data.to_excel(\"merged.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac48ed",
   "metadata": {},
   "source": [
    "Next we will merge the data with employment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8d35a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the employment data\n",
    "employment_data = pd.read_excel('employment.xlsx')\n",
    "\n",
    "# Load the merged data\n",
    "merged_data = pd.read_excel('merged.xlsx')\n",
    "\n",
    "# Merge the merged_data and employment_data DataFrames on the 'FIPS' column\n",
    "merged_data = merged_data.merge(employment_data, on='FIPS')\n",
    "\n",
    "# Export the data \n",
    "merged_data.to_excel(\"data.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a80549",
   "metadata": {},
   "source": [
    "now to clean some problematic values from proportion_white_2013 and normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78b16bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('data.xlsx')\n",
    "\n",
    "# Replace inf and -inf values with NaN\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN values with a suitable value, e.g., 1\n",
    "data['Proportion_White_2013'].fillna(1, inplace=True)\n",
    "\n",
    "# Clip values greater than 1 to 1\n",
    "data['Proportion_White_2013'] = data['Proportion_White_2013'].clip(upper=1)\n",
    "\n",
    "# Save the cleaned data\n",
    "data.to_excel(\"cleaned_data.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a79c4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('cleaned_data.xlsx')\n",
    "\n",
    "# Identify the columns to normalize, excluding 'FIPS'\n",
    "columns_to_normalize = [col for col in data.columns if col not in ['County', 'FIPS']]\n",
    "\n",
    "# Apply Standard Scaling to the selected columns\n",
    "scaler = StandardScaler()\n",
    "normalized_values = scaler.fit_transform(data[columns_to_normalize])\n",
    "\n",
    "# Replace the original columns with the normalized values\n",
    "normalized_data = data.copy()\n",
    "normalized_data[columns_to_normalize] = normalized_values\n",
    "\n",
    "# Export the normalized data to an Excel file\n",
    "normalized_data.to_excel(\"normalized_data.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
